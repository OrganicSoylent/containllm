apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama-large
  namespace: ollama
  labels:
    app: ollama
    model: large
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ollama
      model: large
  template:
    metadata:
      labels:
        app: ollama
        model: large
    spec:
      containers:
        - name: ollama
          image: ollama/ollama:latest
          ports:
            - containerPort: 11434
          volumeMounts:
            - mountPath: /root/.ollama
              name: ollama-storage
          envFrom:
          - configMapRef:
              name: ollama-large-cm
### Overriding default CMD (ollama serve) is necessary for ollama env variables take effect
          command: ["/bin/sh", "-c"]
          args:
            - "ollama serve"
### PostStart installation of LLM models (see configmap)
          # lifecycle:
          #   postStart:
          #     exec:
          #       command:
          #         - "/bin/sh"
          #         - "-c"
          #         - |
          #           ollama pull $MODEL_A && \
          #           ollama pull $MODEL_B && \
          #           ollama pull $MODEL_C
      volumes:
        - name: ollama-storage
          emptyDir: {}